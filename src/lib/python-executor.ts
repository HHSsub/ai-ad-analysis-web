import { spawn } from 'child_process';
import * as fs from 'fs';
import * as path from 'path';

export interface CollectorOptions {
  maxAds?: number;
  searchQueries?: string[];
}

export interface CollectorResult {
  success: boolean;
  output?: string;
  error?: string;
}

export interface DatabaseStats {
  total_ads: number;
  pending: number;
  completed: number;
  failed: number;
  latest_collection?: string;
}

export class PythonExecutor {
  private dbPath: string;
  
  constructor() {
    this.dbPath = path.join(process.cwd(), 'youtube_ads.db');
  }
  
  /**
   * Python ê´‘ê³  ìˆ˜ì§‘ê¸° ì‹¤í–‰ (ë¹„ëŒ€í™”ì‹)
   */
  async executeCollector(options: CollectorOptions = {}): Promise<CollectorResult> {
    const { maxAds = 20, searchQueries } = options;
    
    return new Promise((resolve) => {
      // Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¹„ëŒ€í™”ì‹ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„¤ì •
      const pythonCode = this.generatePythonScript(maxAds, searchQueries);
      
      // ì„ì‹œ íŒŒì¼ì— Python ì½”ë“œ ì‘ì„±
      const tempScript = path.join(process.cwd(), 'temp_collector.py');
      fs.writeFileSync(tempScript, pythonCode);
      
      const pythonProcess = spawn('python3', [tempScript], {
        cwd: process.cwd(),
        env: {
          ...process.env,
          APIFY_TOKEN: process.env.APIFY_TOKEN || '',
          SERPAPI_KEY: process.env.SERPAPI_KEY || '646e6386e54a3e331122aa9460166830bcdbd35c89283b857dcf66901e11db2a',
          PYTHONUNBUFFERED: '1'  // Python ì¶œë ¥ ë²„í¼ë§ ë°©ì§€
        },
        stdio: ['pipe', 'pipe', 'pipe']
      });
      
      let output = '';
      let errorOutput = '';
      
      // í‘œì¤€ ì…ë ¥ ë‹«ê¸° (ëŒ€í™”ì‹ ì…ë ¥ ë°©ì§€)
      pythonProcess.stdin.end();
      
      pythonProcess.stdout.on('data', (data) => {
        const text = data.toString();
        output += text;
        console.log(`[Python Collector] ${text.trim()}`);
      });
      
      pythonProcess.stderr.on('data', (data) => {
        const text = data.toString();
        errorOutput += text;
        console.error(`[Python Collector Error] ${text.trim()}`);
      });
      
      pythonProcess.on('close', (code) => {
        // ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try {
          fs.unlinkSync(tempScript);
        } catch (e) {
          console.warn('ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', e);
        }
        
        if (code === 0) {
          console.log('âœ… Python ê´‘ê³  ìˆ˜ì§‘ ì™„ë£Œ');
          resolve({
            success: true,
            output: output.trim()
          });
        } else {
          console.error(`âŒ Python ê´‘ê³  ìˆ˜ì§‘ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`);
          resolve({
            success: false,
            error: errorOutput || `Process exited with code ${code}`
          });
        }
      });
      
      pythonProcess.on('error', (error) => {
        console.error('âŒ Python í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹¤íŒ¨:', error);
        try {
          fs.unlinkSync(tempScript);
        } catch (e) {}
        resolve({
          success: false,
          error: `Failed to start Python process: ${error.message}`
        });
      });
      
      // íƒ€ì„ì•„ì›ƒ ì„¤ì • (5ë¶„)
      setTimeout(() => {
        pythonProcess.kill('SIGTERM');
        resolve({
          success: false,
          error: 'Python script execution timeout (5 minutes)'
        });
      }, 300000);
    });
  }
  
  /**
   * ë¹„ëŒ€í™”ì‹ Python ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
   */
  private generatePythonScript(maxAds: number, searchQueries?: string[]): string {
    const defaultQueries = [
      "advertisement commercial",
      "product promotion",
      "brand commercial",
      "sponsored content",
      "new product launch"
    ];
    
    const queries = searchQueries || defaultQueries;
    
    return `#!/usr/bin/env python3
import os
import sys
import sqlite3
import requests
import time
import json
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class AdVideoInfo:
    title: str
    url: str
    note: str

class YouTubeAdsDatabase:
    def __init__(self, db_path: str = "youtube_ads.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS youtube_ads (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                url TEXT UNIQUE NOT NULL,
                note TEXT,
                search_query TEXT,
                api_source TEXT,
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                analyzed_at TIMESTAMP NULL,
                analysis_status TEXT DEFAULT 'pending'
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS search_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query TEXT UNIQUE NOT NULL,
                api_source TEXT NOT NULL,
                last_collected TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                total_found INTEGER DEFAULT 0,
                success_count INTEGER DEFAULT 0
            )
        """)
        
        conn.commit()
        conn.close()
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def should_collect(self, search_query: str, api_source: str, hours: int = 24) -> bool:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT last_collected FROM search_history 
                WHERE query = ? AND api_source = ?
            """, (search_query, api_source))
            
            row = cursor.fetchone()
            if row:
                last_collected = datetime.fromisoformat(row[0])
                time_diff = datetime.now() - last_collected
                should_collect = time_diff.total_seconds() > hours * 3600
                print(f"   ğŸ• ë§ˆì§€ë§‰ ìˆ˜ì§‘: {last_collected.strftime('%Y-%m-%d %H:%M')}")
                print(f"   â° ê²½ê³¼ ì‹œê°„: {time_diff.total_seconds() / 3600:.1f}ì‹œê°„")
                return should_collect
            else:
                print(f"   ğŸ†• ì‹ ê·œ ê²€ìƒ‰ì–´: ìˆ˜ì§‘ í•„ìš”")
                return True
                
        finally:
            conn.close()
    
    def save_ads(self, ads: list, search_query: str, api_source: str) -> int:
        if not ads:
            return 0
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        new_count = 0
        
        try:
            for ad in ads:
                cursor.execute("""
                    INSERT OR IGNORE INTO youtube_ads 
                    (title, url, note, search_query, api_source)
                    VALUES (?, ?, ?, ?, ?)
                """, (ad.title, ad.url, ad.note, search_query, api_source))
                
                if cursor.rowcount > 0:
                    new_count += 1
            
            cursor.execute("""
                INSERT OR REPLACE INTO search_history (query, api_source, total_found, success_count, last_collected)
                VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
            """, (search_query, api_source, len(ads), new_count))
            
            conn.commit()
            print(f"   ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì „ì²´ {len(ads)}ê°œ ì¤‘ ì‹ ê·œ {new_count}ê°œ")
            return new_count
            
        finally:
            conn.close()

class YouTubeAdsCollector:
    def __init__(self):
        self.db = YouTubeAdsDatabase()
        self.serp_api_key = "${process.env.SERPAPI_KEY || '646e6386e54a3e331122aa9460166830bcdbd35c89283b857dcf66901e11db2a'}"
    
    def collect_ads_with_serpapi(self, search_query: str) -> List[AdVideoInfo]:
        if not self.serp_api_key:
            print("SerpAPI í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return []
        
        if not self.db.should_collect(search_query, "SerpAPI", hours=6):
            print(f"â­ï¸ SerpAPI '{search_query}' ìˆ˜ì§‘ ê±´ë„ˆë›°ê¸° (6ì‹œê°„ ì´ë‚´ ìˆ˜ì§‘ë¨)")
            return []
        
        url = "https://serpapi.com/search"
        params = {
            "engine": "youtube",
            "search_query": search_query,
            "api_key": self.serp_api_key,
            "num": 20
        }
        
        try:
            print(f"ğŸ“¡ SerpAPIë¡œ '{search_query}' ìˆ˜ì§‘ ì¤‘...")
            response = requests.get(url, params=params, timeout=60)
            
            if response.status_code == 200:
                data = response.json()
                
                if "error" in data:
                    print(f"SerpAPI ì˜¤ë¥˜: {data['error']}")
                    return []
                
                ad_videos = []
                
                # ê´‘ê³  ê²°ê³¼ ì²˜ë¦¬
                ads_results = data.get("ads_results", [])
                for ad in ads_results:
                    title = ad.get('title', 'Unknown Title').strip()
                    link = ad.get('link', '')
                    
                    if link and 'youtube.com' in link:
                        note = f"ğŸ“¢ SerpAPI ê´‘ê³ "
                        if 'views' in ad:
                            note += f" | ì¡°íšŒìˆ˜: {ad['views']}"
                        
                        ad_video = AdVideoInfo(
                            title=title[:150],
                            url=link,
                            note=note[:200]
                        )
                        ad_videos.append(ad_video)
                
                # ê´‘ê³ ì„± í‚¤ì›Œë“œ ë¹„ë””ì˜¤ í•„í„°ë§
                video_results = data.get("video_results", [])
                ad_keywords = ['ad', 'advertisement', 'commercial', 'sponsored', 'promo', 'review']
                
                for video in video_results:
                    title = video.get('title', '').strip()
                    link = video.get('link', '')
                    
                    if any(keyword in title.lower() for keyword in ad_keywords):
                        if link and 'youtube.com' in link:
                            note = f"ğŸ¬ SerpAPI ê´‘ê³ ì„± ì½˜í…ì¸ "
                            if 'views' in video:
                                note += f" | ì¡°íšŒìˆ˜: {video['views']}"
                            
                            ad_video = AdVideoInfo(
                                title=title[:150],
                                url=link,
                                note=note[:200]
                            )
                            ad_videos.append(ad_video)
                
                print(f"   âœ… ìˆ˜ì§‘ëœ ê´‘ê³ : {len(ad_videos)}ê°œ")
                return ad_videos
                
            else:
                print(f"SerpAPI ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
                return []
                
        except Exception as e:
            print(f"SerpAPI ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def collect_all_ads(self, search_queries: List[str], max_ads_per_query: int = 30) -> Dict[str, int]:
        results = {
            'total_collected': 0,
            'new_ads': 0,
            'serpapi': 0,
            'skipped_queries': 0
        }
        
        print(f"ğŸš€ ê´‘ê³  ìˆ˜ì§‘ ì‹œì‘ - {len(search_queries)}ê°œ ê²€ìƒ‰ì–´")
        
        for i, query in enumerate(search_queries, 1):
            print(f"\\nğŸ“ [{i}/{len(search_queries)}] ê²€ìƒ‰ì–´: '{query}'")
            
            collected_this_query = 0
            
            # SerpAPI ìˆ˜ì§‘
            serpapi_ads = self.collect_ads_with_serpapi(query)
            if serpapi_ads:
                new_count = self.db.save_ads(serpapi_ads, query, "SerpAPI")
                results['total_collected'] += len(serpapi_ads)
                results['new_ads'] += new_count
                results['serpapi'] += len(serpapi_ads)
                collected_this_query += len(serpapi_ads)
                time.sleep(1)  # API ìš”ì²­ ê°„ê²©
            
            if collected_this_query == 0:
                results['skipped_queries'] += 1
                print(f"   â­ï¸ ê±´ë„ˆë›°ê¸° (ìµœê·¼ ìˆ˜ì§‘ë¨ ë˜ëŠ” ì˜¤ë¥˜)")
            else:
                print(f"   âœ… ì´ë²ˆ ì¿¼ë¦¬ ìˆ˜ì§‘: {collected_this_query}ê°œ")
        
        return results

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    print("ğŸš€ YouTube ê´‘ê³  ë™ì˜ìƒ ìë™ ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 60)
    
    collector = YouTubeAdsCollector()
    
    # ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
    search_queries = ${JSON.stringify(queries)}
    max_ads = ${maxAds}
    
    try:
        # ìˆ˜ì§‘ ì‹¤í–‰
        print(f"ğŸ¯ ê²€ìƒ‰ì–´ë‹¹ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜: {max_ads}")
        results = collector.collect_all_ads(search_queries, max_ads)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\\n" + "="*60)
        print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"âœ… ì´ ìˆ˜ì§‘: {results['total_collected']}ê°œ")
        print(f"ğŸ†• ì‹ ê·œ ê´‘ê³ : {results['new_ads']}ê°œ")
        print(f"ğŸ” SerpAPI: {results['serpapi']}ê°œ")
        print(f"â­ï¸ ê±´ë„ˆë›´ ê²€ìƒ‰ì–´: {results['skipped_queries']}ê°œ")
        
        if results['new_ads'] > 0:
            print(f"\\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ! {results['new_ads']}ê°œ ì‹ ê·œ ê´‘ê³ ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\\nğŸ’¡ ì‹ ê·œ ê´‘ê³ ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¤‘ë³µ ì œê±°ë¨)")
            
        # JSON í˜•íƒœë¡œ ê²°ê³¼ ì¶œë ¥ (ì›¹ì—ì„œ íŒŒì‹±ìš©)
        print("\\nRESULT_JSON:" + json.dumps(results))
            
    except Exception as e:
        print(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
`;
  }
  
  /**
   * ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ (SQLite ì§ì ‘ ì¡°íšŒ)
   */
  async getStats(): Promise<DatabaseStats> {
    return new Promise((resolve) => {
      if (!fs.existsSync(this.dbPath)) {
        resolve({
          total_ads: 0,
          pending: 0,
          completed: 0,
          failed: 0
        });
        return;
      }
      
      try {
        // SQLite3 ë°”ì´ë„ˆë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš©
        const sqlite = spawn('sqlite3', [this.dbPath, '-json', `
          SELECT 
            (SELECT COUNT(*) FROM youtube_ads) as total_ads,
            (SELECT COUNT(*) FROM youtube_ads WHERE analysis_status = 'pending') as pending,
            (SELECT COUNT(*) FROM youtube_ads WHERE analysis_status = 'completed') as completed,
            (SELECT COUNT(*) FROM youtube_ads WHERE analysis_status = 'failed') as failed,
            (SELECT MAX(collected_at) FROM youtube_ads) as latest_collection
        `]);
        
        let output = '';
        sqlite.stdout.on('data', (data) => {
          output += data.toString();
        });
        
        sqlite.on('close', (code) => {
          try {
            const result = JSON.parse(output.trim())[0] || {};
            resolve({
              total_ads: result.total_ads || 0,
              pending: result.pending || 0,
              completed: result.completed || 0,
              failed: result.failed || 0,
              latest_collection: result.latest_collection
            });
          } catch (e) {
            console.error('í†µê³„ íŒŒì‹± ì‹¤íŒ¨:', e);
            resolve({
              total_ads: 0,
              pending: 0,
              completed: 0,
              failed: 0
            });
          }
        });
        
        sqlite.on('error', (error) => {
          console.error('SQLite3 ì‹¤í–‰ ì˜¤ë¥˜:', error);
          resolve({
            total_ads: 0,
            pending: 0,
            completed: 0,
            failed: 0
          });
        });
        
      } catch (error) {
        console.error('í†µê³„ ì¡°íšŒ ì˜¤ë¥˜:', error);
        resolve({
          total_ads: 0,
          pending: 0,
          completed: 0,
          failed: 0
        });
      }
    });
  }
  
  /**
   * ìµœê·¼ ìˆ˜ì§‘ëœ ê´‘ê³  ë°ì´í„° ì¡°íšŒ
   */
  async readDatabase(limit: number = 100): Promise<any[]> {
    return new Promise((resolve) => {
      if (!fs.existsSync(this.dbPath)) {
        resolve([]);
        return;
      }
      
      try {
        const sqlite = spawn('sqlite3', [this.dbPath, '-json', `
          SELECT id, title, url, note, search_query, api_source, 
                 collected_at, analyzed_at, analysis_status
          FROM youtube_ads 
          ORDER BY collected_at DESC 
          LIMIT ${limit}
        `]);
        
        let output = '';
        sqlite.stdout.on('data', (data) => {
          output += data.toString();
        });
        
        sqlite.on('close', (code) => {
          try {
            const results = JSON.parse(output.trim()) || [];
            resolve(results);
          } catch (e) {
            console.error('ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨:', e);
            resolve([]);
          }
        });
        
        sqlite.on('error', (error) => {
          console.error('ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜:', error);
          resolve([]);
        });
        
      } catch (error) {
        resolve([]);
      }
    });
  }
}
