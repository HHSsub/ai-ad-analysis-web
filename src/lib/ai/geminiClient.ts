import limiter from "@/lib/limiter/bottleneck";
import { GoogleGenerativeAI, type Part } from "@google/generative-ai";

type RetriableError = {
  status?: number;
  message?: string;
  response?: {
    status?: number;
    headers?: any;
  };
};

// âœ… ê°•ì œë¡œ 2.5 ì´ìƒ ëª¨ë¸ë§Œ ì‚¬ìš© - 1.5, 2.0 ì ˆëŒ€ ê¸ˆì§€
const DEFAULT_MODEL = process.env.GEMINI_MODEL || "gemini-2.5-flash";
const FALLBACK_MODELS = (process.env.GEMINI_FALLBACK_MODELS || "gemini-2.5-pro,gemini-2.5-flash-8b")
  .split(",")
  .map((s) => s.trim())
  .filter(Boolean)
  .filter(model => {
    // 1.5ë‚˜ 2.0 ëª¨ë¸ ì™„ì „ ì°¨ë‹¨
    if (model.includes('1.5') || model.includes('2.0')) {
      console.warn(`âš ï¸ êµ¬ì‹ ëª¨ë¸ ì°¨ë‹¨ë¨: ${model}`);
      return false;
    }
    return true;
  });

// ìµœì†Œ ì¬ì‹œë„(ë¹ˆ ì‘ë‹µ/ì¼ì‹œ ì˜¤ë¥˜ë§Œ)
const MAX_RETRIES = parseInt(process.env.GEMINI_MAX_RETRIES || "2", 10);
const BASE_MS = parseInt(process.env.GEMINI_BACKOFF_BASE_MS || "800", 10);
const CAP_MS = parseInt(process.env.GEMINI_BACKOFF_CAP_MS || "8000", 10);

function sleep(ms: number) {
  return new Promise((res) => setTimeout(res, ms));
}

function isRetriable(err: RetriableError) {
  const status = err?.response?.status ?? err?.status;
  if (!status) return true;
  if (status === 429) return true;
  if (status >= 500 && status <= 599) return true;
  return false;
}

function backoffMs(attempt: number) {
  const exp = Math.min(CAP_MS, BASE_MS * Math.pow(2, attempt));
  const jitter = Math.random() * 0.2 * exp;
  return Math.min(CAP_MS, Math.floor(exp * 0.9 + jitter));
}

export type GenerateOptions = {
  parts: Part[];
  model?: string;
  systemInstruction?: string;
  generationConfig?: Record<string, any>;
  safetySettings?: Record<string, any>;
  maxRetries?: number;
  onRetry?: (info: {
    attempt: number;
    delayMs: number;
    status?: number;
    model: string;
    error: unknown;
  }) => void;
};

export async function generateContentWithRetry(opts: GenerateOptions) {
  const {
    parts,
    model = DEFAULT_MODEL,
    systemInstruction,
    generationConfig,
    safetySettings,
    maxRetries = MAX_RETRIES,
    onRetry,
  } = opts;

  // âœ… êµ¬ì‹ ëª¨ë¸ ì™„ì „ ì°¨ë‹¨
  let requestedModel = model;
  if (requestedModel.includes('1.5') || requestedModel.includes('2.0')) {
    console.warn(`âš ï¸ êµ¬ì‹ ëª¨ë¸ ${requestedModel} ì°¨ë‹¨, gemini-2.5-flashë¡œ ê°•ì œ ë³€ê²½`);
    requestedModel = 'gemini-2.5-flash';
  }

  // âœ… í´ë°± ëª¨ë¸ë“¤ë„ ê²€ì¦
  const validModels = [requestedModel, ...FALLBACK_MODELS].filter(m => 
    !m.includes('1.5') && !m.includes('2.0')
  );

  if (validModels.length === 0) {
    validModels.push('gemini-2.5-flash'); // ìµœì¢… ì•ˆì „ì¥ì¹˜
  }

  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");
  let lastError: unknown;

  for (let mIndex = 0; mIndex < validModels.length; mIndex++) {
    const currentModel = validModels[mIndex];
    console.log(`ğŸ¤– Gemini ëª¨ë¸ ì‚¬ìš©: ${currentModel}`);

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const modelClient = genAI.getGenerativeModel({
          model: currentModel,
          systemInstruction,
        });

        const result = await limiter.schedule(() =>
          modelClient.generateContent({
            contents: [{ role: "user", parts }],
            generationConfig: {
              temperature: 0.3,
              maxOutputTokens: 8000,
              ...generationConfig,
            },
            safetySettings,
          } as any)
        );

        const rawResp = result?.response;
        const text = rawResp?.text?.() ?? "";
        const candidates = (rawResp as any)?.candidates ?? [];

        // ë¹ˆ ì‘ë‹µ/í›„ë³´ ì—†ìŒë§Œ ì¬ì‹œë„
        if (!text || !text.trim() || candidates.length === 0) {
          const err = new Error("Empty response from Gemini");
          (err as any).response = { status: 503 };
          throw err;
        }

        console.log(`âœ… Gemini ì‘ë‹µ ì„±ê³µ: ${currentModel} (ê¸¸ì´: ${text.length})`);
        return { text, response: rawResp, model: currentModel };
      } catch (error: any) {
        lastError = error;
        console.log(`âš ï¸ Gemini ì˜¤ë¥˜ [${currentModel}] ì‹œë„${attempt+1}: ${error.message}`);
        
        if (!isRetriable(error) || attempt === maxRetries) break;
        const delay = backoffMs(attempt);
        onRetry?.({
          attempt: attempt + 1,
          delayMs: delay,
          status: error?.response?.status ?? error?.status,
          model: currentModel,
          error,
        });
        await sleep(delay);
      }
    }
    // ë‹¤ìŒ ëª¨ë¸ë¡œ í´ë°±
  }

  const status = (lastError as any)?.response?.status ?? (lastError as any)?.status;
  const message = (lastError as any)?.message || "Gemini generateContent failed.";
  const err = new Error(`[Gemini] ${status || ""} ${message}`.trim());
  (err as any).cause = lastError;
  throw err;
}
