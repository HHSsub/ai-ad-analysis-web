#!/usr/bin/env python3
"""
YouTube ê´‘ê³  ìˆ˜ì§‘ê¸° ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ì •
"""

import sqlite3
import os
from datetime import datetime, timedelta

class YouTubeAdsDatabase:
    """YouTube ê´‘ê³  ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, db_path: str = "youtube_ads.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # 1. ê´‘ê³  ì˜ìƒ ì •ë³´ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS youtube_ads (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                url TEXT UNIQUE NOT NULL,  -- ì¤‘ë³µ ë°©ì§€
                note TEXT,
                search_query TEXT,         -- ì–´ë–¤ ê²€ìƒ‰ì–´ë¡œ ì°¾ì•˜ëŠ”ì§€ ì¶”ì 
                api_source TEXT,           -- Apify ë˜ëŠ” SerpAPI
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                analyzed_at TIMESTAMP NULL, -- ë¶„ì„ ì™„ë£Œ ì‹œê°„
                analysis_status TEXT DEFAULT 'pending'  -- pending, completed, failed
            )
        """)
        
        # 2. ê²€ìƒ‰ ê¸°ë¡ í…Œì´ë¸” (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS search_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query TEXT UNIQUE NOT NULL,
                api_source TEXT NOT NULL,   -- Apify ë˜ëŠ” SerpAPI
                last_collected TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                total_found INTEGER DEFAULT 0,
                success_count INTEGER DEFAULT 0
            )
        """)
        
        # 3. ë¶„ì„ í í…Œì´ë¸” (ì›¹ì„œë¹„ìŠ¤ ì—°ë™ìš©)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS analysis_queue (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                youtube_ad_id INTEGER,
                priority INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                processed_at TIMESTAMP NULL,
                status TEXT DEFAULT 'waiting',  -- waiting, processing, completed, failed
                error_message TEXT NULL,
                FOREIGN KEY (youtube_ad_id) REFERENCES youtube_ads (id)
            )
        """)
        
        # 4. ì›¹ì„œë¹„ìŠ¤ ì—°ë™ ë¡œê·¸ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS sync_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                sync_type TEXT NOT NULL,  -- 'fetch_new', 'update_status' ë“±
                records_count INTEGER,
                success BOOLEAN,
                error_message TEXT NULL,
                sync_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_ads_url ON youtube_ads(url)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_ads_collected_at ON youtube_ads(collected_at)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_ads_analysis_status ON youtube_ads(analysis_status)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_search_query ON search_history(query)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_queue_status ON analysis_queue(status)")
        
        conn.commit()
        conn.close()
        
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")
    
    def should_collect(self, search_query: str, api_source: str, hours: int = 24) -> bool:
        """
        ê²€ìƒ‰ì–´ë³„ë¡œ ìµœê·¼ ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸ (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)
        
        Args:
            search_query: ê²€ìƒ‰ì–´
            api_source: API ì†ŒìŠ¤ (Apify ë˜ëŠ” SerpAPI)
            hours: ì¤‘ë³µ ë°©ì§€ ì‹œê°„ (ê¸°ë³¸ 24ì‹œê°„)
            
        Returns:
            True: ìˆ˜ì§‘ í•„ìš”, False: ìˆ˜ì§‘ ë¶ˆí•„ìš”
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT last_collected FROM search_history 
                WHERE query = ? AND api_source = ?
            """, (search_query, api_source))
            
            row = cursor.fetchone()
            if row:
                last_collected = datetime.fromisoformat(row[0])
                time_diff = datetime.now() - last_collected
                should_collect = time_diff.total_seconds() > hours * 3600
                
                print(f"   ğŸ• ë§ˆì§€ë§‰ ìˆ˜ì§‘: {last_collected.strftime('%Y-%m-%d %H:%M')}")
                print(f"   â° ê²½ê³¼ ì‹œê°„: {time_diff.total_seconds() / 3600:.1f}ì‹œê°„")
                print(f"   ğŸ¯ ìˆ˜ì§‘ í•„ìš”: {'Yes' if should_collect else 'No'}")
                
                return should_collect
            else:
                print(f"   ğŸ†• ì‹ ê·œ ê²€ìƒ‰ì–´: ìˆ˜ì§‘ í•„ìš”")
                return True
                
        finally:
            conn.close()
    
    def save_ads(self, ads: list, search_query: str, api_source: str) -> int:
        """
        ê´‘ê³  ë°ì´í„°ë¥¼ DBì— ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì‹ ê·œ ê´‘ê³  ê°œìˆ˜
        """
        if not ads:
            return 0
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        new_count = 0
        
        try:
            for ad in ads:
                # ê´‘ê³  ë°ì´í„° ì €ì¥ (ì¤‘ë³µ ì‹œ ë¬´ì‹œ)
                cursor.execute("""
                    INSERT OR IGNORE INTO youtube_ads 
                    (title, url, note, search_query, api_source)
                    VALUES (?, ?, ?, ?, ?)
                """, (ad.title, ad.url, ad.note, search_query, api_source))
                
                if cursor.rowcount > 0:
                    new_count += 1
                    ad_id = cursor.lastrowid
                    
                    # ë¶„ì„ íì— ì¶”ê°€
                    cursor.execute("""
                        INSERT INTO analysis_queue (youtube_ad_id, priority)
                        VALUES (?, ?)
                    """, (ad_id, 1))
            
            # ê²€ìƒ‰ ê¸°ë¡ ì—…ë°ì´íŠ¸
            cursor.execute("""
                INSERT INTO search_history (query, api_source, total_found, success_count)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(query) DO UPDATE SET
                    last_collected = CURRENT_TIMESTAMP,
                    total_found = total_found + ?,
                    success_count = success_count + ?
            """, (search_query, api_source, len(ads), new_count, len(ads), new_count))
            
            conn.commit()
            
            print(f"   ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì „ì²´ {len(ads)}ê°œ ì¤‘ ì‹ ê·œ {new_count}ê°œ")
            return new_count
            
        finally:
            conn.close()
    
    def get_pending_analysis(self, limit: int = 100) -> list:
        """
        ë¶„ì„ ëŒ€ê¸° ì¤‘ì¸ ê´‘ê³  ëª©ë¡ ì¡°íšŒ (ì›¹ì„œë¹„ìŠ¤ ì—°ë™ìš©)
        
        Returns:
            [{'id': 1, 'title': '...', 'url': '...', 'note': '...'}, ...]
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT a.id, a.title, a.url, a.note, a.collected_at
                FROM youtube_ads a
                WHERE a.analysis_status = 'pending'
                ORDER BY a.collected_at DESC
                LIMIT ?
            """, (limit,))
            
            rows = cursor.fetchall()
            
            return [
                {
                    'id': row[0],
                    'title': row[1],
                    'url': row[2],
                    'note': row[3],
                    'collected_at': row[4]
                }
                for row in rows
            ]
            
        finally:
            conn.close()
    
    def update_analysis_status(self, ad_id: int, status: str, error_message: str = None):
        """
        ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì›¹ì„œë¹„ìŠ¤ì—ì„œ í˜¸ì¶œ)
        
        Args:
            ad_id: ê´‘ê³  ID
            status: 'completed' ë˜ëŠ” 'failed'
            error_message: ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            if status == 'completed':
                cursor.execute("""
                    UPDATE youtube_ads 
                    SET analysis_status = ?, analyzed_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (status, ad_id))
            else:
                cursor.execute("""
                    UPDATE youtube_ads 
                    SET analysis_status = ?, analyzed_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (status, ad_id))
            
            # ë¶„ì„ íì—ì„œ ì œê±°
            cursor.execute("""
                UPDATE analysis_queue 
                SET status = ?, processed_at = CURRENT_TIMESTAMP, error_message = ?
                WHERE youtube_ad_id = ?
            """, (status, error_message, ad_id))
            
            conn.commit()
            
        finally:
            conn.close()
    
    def get_statistics(self) -> dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            stats = {}
            
            # ì „ì²´ ê´‘ê³  ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM youtube_ads")
            stats['total_ads'] = cursor.fetchone()[0]
            
            # ë¶„ì„ ìƒíƒœë³„ ê°œìˆ˜
            cursor.execute("""
                SELECT analysis_status, COUNT(*) 
                FROM youtube_ads 
                GROUP BY analysis_status
            """)
            status_counts = dict(cursor.fetchall())
            stats['pending'] = status_counts.get('pending', 0)
            stats['completed'] = status_counts.get('completed', 0)
            stats['failed'] = status_counts.get('failed', 0)
            
            # API ì†ŒìŠ¤ë³„ ê°œìˆ˜
            cursor.execute("""
                SELECT api_source, COUNT(*) 
                FROM youtube_ads 
                GROUP BY api_source
            """)
            source_counts = dict(cursor.fetchall())
            stats['apify_count'] = source_counts.get('Apify', 0)
            stats['serpapi_count'] = source_counts.get('SerpAPI', 0)
            
            # ìµœê·¼ ìˆ˜ì§‘ ì‹œê°„
            cursor.execute("""
                SELECT MAX(collected_at) FROM youtube_ads
            """)
            latest = cursor.fetchone()[0]
            stats['latest_collection'] = latest
            
            return stats
            
        finally:
            conn.close()
    
    def export_for_analysis(self, status: str = 'pending', format: str = 'json') -> str:
        """
        ë¶„ì„ìš© ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        
        Args:
            status: 'pending', 'all' ë“±
            format: 'json', 'csv'
            
        Returns:
            ë‚´ë³´ë‚¸ íŒŒì¼ ê²½ë¡œ
        """
        import json
        import csv
        from datetime import datetime
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            if status == 'all':
                cursor.execute("""
                    SELECT id, title, url, note, collected_at, analysis_status
                    FROM youtube_ads ORDER BY collected_at DESC
                """)
            else:
                cursor.execute("""
                    SELECT id, title, url, note, collected_at, analysis_status
                    FROM youtube_ads WHERE analysis_status = ?
                    ORDER BY collected_at DESC
                """, (status,))
            
            rows = cursor.fetchall()
            data = [
                {
                    'id': row[0],
                    'title': row[1],
                    'url': row[2],
                    'note': row[3],
                    'collected_at': row[4],
                    'analysis_status': row[5]
                }
                for row in rows
            ]
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if format == 'json':
                filename = f"youtube_ads_{status}_{timestamp}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            else:  # CSV
                filename = f"youtube_ads_{status}_{timestamp}.csv"
                with open(filename, 'w', newline='', encoding='utf-8') as f:
                    if data:
                        writer = csv.DictWriter(f, fieldnames=data[0].keys())
                        writer.writeheader()
                        writer.writerows(data)
            
            print(f"ğŸ“ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filename} ({len(data)}ê°œ ë ˆì½”ë“œ)")
            return filename
            
        finally:
            conn.close()

def main():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë° í…ŒìŠ¤íŠ¸"""
    print("ğŸ—„ï¸ YouTube ê´‘ê³  ìˆ˜ì§‘ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •")
    print("=" * 50)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    db = YouTubeAdsDatabase()
    
    # í†µê³„ ì¶œë ¥
    stats = db.get_statistics()
    print(f"\nğŸ“Š í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:")
    print(f"   ì „ì²´ ê´‘ê³ : {stats['total_ads']}ê°œ")
    print(f"   ë¶„ì„ ëŒ€ê¸°: {stats['pending']}ê°œ")
    print(f"   ë¶„ì„ ì™„ë£Œ: {stats['completed']}ê°œ")
    print(f"   ë¶„ì„ ì‹¤íŒ¨: {stats['failed']}ê°œ")
    print(f"   Apify ìˆ˜ì§‘: {stats['apify_count']}ê°œ")
    print(f"   SerpAPI ìˆ˜ì§‘: {stats['serpapi_count']}ê°œ")
    
    if stats['latest_collection']:
        print(f"   ìµœê·¼ ìˆ˜ì§‘: {stats['latest_collection']}")
    
    print(f"\nâœ… ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ!")
    print(f"   íŒŒì¼ ìœ„ì¹˜: {db.db_path}")

if __name__ == "__main__":
    main()